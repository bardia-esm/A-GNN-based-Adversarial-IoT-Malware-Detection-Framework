{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "import re\n",
    "\n",
    "from utils import read_graph_data, read_pickle, plot_histogram, process_graph_data, get_processed_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Dataset\n",
    "class CFG(Dataset):\n",
    "    def __init__(self, graph_addr_list, root, label_transformer, transform=None, pre_transform=None):\n",
    "        self.graph_addr_list = graph_addr_list\n",
    "        self.label_transformer = label_transformer\n",
    "        super(CFG, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'data_{file_idx}.pt' for file_idx in range(len(self.graph_addr_list))]\n",
    "\n",
    "    def process(self):\n",
    "        graph_data_mapping = []\n",
    "        one_hot_transform = T.OneHotDegree(max_degree = 187, cat = False, in_degree = True)\n",
    "\n",
    "        for graph_idx, graph_addr in enumerate(self.graph_addr_list):\n",
    "            try:\n",
    "                graph_data = read_graph_data(graph_addr)\n",
    "\n",
    "                raw_edges = graph_data['edge_list']\n",
    "                raw_nodes = list(graph_data['node_dict'].keys())\n",
    "\n",
    "                if 'benign' in graph_addr:\n",
    "                    y = 'benign'\n",
    "                elif 'tsunami' in graph_addr:\n",
    "                    y = 'tsunami'\n",
    "                elif 'mirai' in graph_addr:\n",
    "                    y = 'mirai'\n",
    "                elif 'gafgyt' in graph_addr:\n",
    "                    y = 'gafgyt'\n",
    "\n",
    "                unique_node_idx_counter = 0\n",
    "                node_mapping = {}\n",
    "                edges = [[], []]\n",
    "\n",
    "                for node in raw_nodes:\n",
    "                    node_mapping[str(node)] = unique_node_idx_counter\n",
    "                    unique_node_idx_counter += 1\n",
    "\n",
    "                for edge in raw_edges:\n",
    "                    edges[0].append(node_mapping[str(edge[0])])\n",
    "                    edges[1].append(node_mapping[str(edge[1])])\n",
    "\n",
    "                edge_idx = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(self.label_transformer.transform([y]), dtype=torch.long)\n",
    "                x = None\n",
    "                data = Data(x=x, edge_index=edge_idx, y=y)\n",
    "                data = one_hot_transform(data)\n",
    "                \n",
    "                if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                    continue\n",
    "\n",
    "                if self.pre_transform is not None:\n",
    "                    data = self.pre_transform(data)\n",
    "\n",
    "                torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(graph_idx)))\n",
    "            except Exception as e:\n",
    "                print(graph_addr, e)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_train_graph_list = glob(\"datasets/normal_dataset/benign/train/*\")\n",
    "benign_test_graph_list = glob(\"datasets/normal_dataset/benign/test/*\")\n",
    "print('benign', len(benign_train_graph_list), len(benign_test_graph_list))\n",
    "\n",
    "tsunami_train_graph_list = glob(\"datasets/normal_dataset/tsunami/train/*\")\n",
    "tsunami_test_graph_list = glob(\"datasets/normal_dataset/tsunami/test/*\")\n",
    "print('tsunami', len(tsunami_train_graph_list), len(tsunami_test_graph_list))\n",
    "\n",
    "mirai_train_graph_list = glob(\"datasets/normal_dataset/mirai/train/*\")\n",
    "mirai_test_graph_list = glob(\"datasets/normal_dataset/mirai/test/*\")\n",
    "print('mirai', len(mirai_train_graph_list), len(mirai_test_graph_list))\n",
    "\n",
    "gafgyt_train_graph_list = glob(\"datasets/normal_dataset/gafgyt/train/*\")\n",
    "gafgyt_test_graph_list = glob(\"datasets/normal_dataset/gafgyt/test/*\")\n",
    "print('gafgyt', len(gafgyt_train_graph_list), len(gafgyt_test_graph_list))\n",
    "\n",
    "all_train_graphs_list = benign_train_graph_list + tsunami_train_graph_list + gafgyt_train_graph_list + mirai_train_graph_list\n",
    "all_test_graphs_list = benign_test_graph_list + tsunami_test_graph_list + gafgyt_test_graph_list + mirai_test_graph_list\n",
    "\n",
    "print(f'Train: {len(all_train_graphs_list)}, Test: {len(all_test_graphs_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp \n",
    "from torch_geometric.data import Data, Dataset, Batch\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear, Sequential, ReLU\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv, GCNConv, SAGEConv, GATConv, GINConv, global_add_pool\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = ['benign', 'tsunami', 'mirai', 'gafgyt'] # Label Encdoer:  [0 3 2 1]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(selected_classes)\n",
    "print('Label Encdoer: ', le.transform(['benign', 'tsunami', 'mirai', 'gafgyt']))\n",
    "\n",
    "train_dataset = CFG(graph_addr_list = all_train_graphs_list, root='data/train', label_transformer = le)\n",
    "print(f'Number of training graphs: {train_dataset.len()}')\n",
    "\n",
    "test_dataset = CFG(graph_addr_list = all_test_graphs_list, root='data/test', label_transformer = le)\n",
    "benign_test_dataset = CFG(graph_addr_list = benign_test_graph_list, root='data/benign_test', label_transformer = le)\n",
    "gafgyt_test_dataset = CFG(graph_addr_list = gafgyt_test_graph_list, root='data/gafgyt_test', label_transformer = le)\n",
    "mirai_test_dataset = CFG(graph_addr_list = mirai_test_graph_list, root='data/mirai_test', label_transformer = le)\n",
    "tsunami_test_dataset = CFG(graph_addr_list = tsunami_test_graph_list, root='data/tsunami_test', label_transformer = le)\n",
    "print(f'Number of test graphs: {test_dataset.len()} - (Number of benign test graphs: {benign_test_dataset.len()} - Number of gafgyt test graphs: {gafgyt_test_dataset.len()} - Number of mirai test graphs: {mirai_test_dataset.len()} - Number of tsunami test graphs: {tsunami_test_dataset.len()})')\n",
    "\n",
    "adversarial_dir = r\"datasets/adversarial_dataset\"\n",
    "adv_addr_dict = {'adversarial_benign': {'min': [], 'median': [], 'max': []}, 'adversarial_gafgyt': {'min': [], 'median': [], 'max': []}, 'adversarial_mirai': {'min': [], 'median': [], 'max': []}, 'adversarial_tsunami': {'min': [], 'median': [], 'max': []}}\n",
    "for i in glob(adversarial_dir + '/*'):\n",
    "    base_name = os.path.basename(i)\n",
    "    adversarial_graph_data = read_graph_data(i)\n",
    "    re_out = re.search(r\"(benign|gafgyt|mirai|tsunami)_(max|median|min)\", base_name).groups()\n",
    "    adv_addr_dict[f'adversarial_{re_out[0]}'][re_out[1]].append(i)\n",
    "\n",
    "for k, v in adv_addr_dict.items():\n",
    "    print(k, end=': ')\n",
    "    for sub_k, sub_v in v.items():\n",
    "        print(sub_k, len(sub_v), end='  ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, adversarial_dataset, batch_size):\n",
    "    dataset_dict = {\n",
    "        'normal': {\n",
    "            'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True), \n",
    "            'total_test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for k, v in dataset_dict.items():\n",
    "        if k == 'adversarial':\n",
    "            for temp_k, temp_v in v.items():\n",
    "                print(f'Number of {temp_k} Samples: {len(temp_v.dataset)}')\n",
    "        else:\n",
    "            print(f\"Number of {k} samples in train-set: {len(v['train'].dataset)}\", f\"Number of {k} samples in test-set: {len(v['total_test'].dataset)}\")\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_CLASSIFIER(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GNN_CLASSIFIER, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        if self.config['conv_layer_type'].__name__ == 'GCNConv':\n",
    "            self.graphConv_layer_list = torch.nn.ModuleList([self.config['conv_layer_type'](*layer, bias = True) for layer in self.config['layer_size_list']])\n",
    "        elif self.config['conv_layer_type'].__name__ == 'GINConv':\n",
    "            self.graphConv_layer_list = torch.nn.ModuleList()\n",
    "            for layer in self.config['layer_size_list']:\n",
    "                in_mlp = Sequential(\n",
    "                    Linear(layer[0], layer[1], bias = True), \n",
    "                    torch.nn.BatchNorm1d(layer[1]), \n",
    "                    ReLU(), \n",
    "                    Linear(layer[1], layer[1], bias = True))\n",
    "                self.graphConv_layer_list.append(self.config['conv_layer_type'](in_mlp))\n",
    "        elif self.config['conv_layer_type'].__name__ == 'GATConv':\n",
    "            self.graphConv_layer_list = torch.nn.ModuleList()\n",
    "            for layer_idx, layer in enumerate(self.config['layer_size_list']):\n",
    "                if layer_idx == 0:\n",
    "                    self.graphConv_layer_list.append(self.config['conv_layer_type'](*layer, heads = 8, bias = True, dropout = config['dropout']))\n",
    "                elif layer_idx < len(self.config['layer_size_list']) - 1:\n",
    "                    self.graphConv_layer_list.append(self.config['conv_layer_type'](in_channels = layer[0] * 8, out_channels = layer[1], heads = 8, bias = True, dropout = config['dropout']))\n",
    "                else:\n",
    "                    self.graphConv_layer_list.append(self.config['conv_layer_type'](in_channels = layer[0] * 8, out_channels = layer[1], heads = 1, bias = True, dropout = config['dropout']))\n",
    "        elif self.config['conv_layer_type'].__name__ == 'SAGEConv':\n",
    "            self.graphConv_layer_list = torch.nn.ModuleList([self.config['conv_layer_type'](*layer, aggr = config['pooling_option'].__name__.split('_')[1], bias = True) for layer in self.config['layer_size_list']])\n",
    "\n",
    "        if self.config['batch_normalization']:\n",
    "            self.bn_list = torch.nn.ModuleList([torch.nn.BatchNorm1d(layer[1]) for layer in self.config['layer_size_list']])\n",
    "\n",
    "        self.linear_layer_list = torch.nn.ModuleList([Linear(32, 32, bias = True), Linear(32, 4, bias = True)])\n",
    "        self.linear_bn_list = torch.nn.ModuleList([torch.nn.BatchNorm1d(32)])\n",
    "\n",
    "    def forward(self, x_data, edge_index_data, batch):\n",
    "        x, edge_index = x_data, edge_index_data\n",
    "\n",
    "        if self.config['virtual_edges']:\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "\n",
    "        num_layers = len(self.graphConv_layer_list)\n",
    "        for layer_idx, layer in enumerate(self.graphConv_layer_list):\n",
    "            x = layer(x, edge_index)\n",
    "            if self.config['conv_layer_type'].__name__ == 'GCNConv':\n",
    "                if self.config['batch_normalization']:\n",
    "                    x = self.bn_list[layer_idx](x)\n",
    "                x = self.config['activation_func'](x)\n",
    "                if self.config['dropout'] > 0.0 and self.training:\n",
    "                    x = F.dropout(x, p = self.config['dropout'], training = self.training)\n",
    "            elif self.config['conv_layer_type'].__name__ == 'GINConv':\n",
    "                if self.config['batch_normalization']:\n",
    "                    x = self.bn_list[layer_idx](x)\n",
    "                x = self.config['activation_func'](x)\n",
    "                if self.config['dropout'] > 0.0 and self.training: \n",
    "                    x = F.dropout(x, p = self.config['dropout'], training = self.training) \n",
    "            elif self.config['conv_layer_type'].__name__ == 'GATConv':\n",
    "                if self.config['batch_normalization']:\n",
    "                    x = self.bn_list[layer_idx](x)\n",
    "                x = self.config['activation_func'](x)\n",
    "                if self.config['dropout'] > 0.0 and self.training: \n",
    "                    x = F.dropout(x, p = self.config['dropout'], training = self.training)\n",
    "            elif self.config['conv_layer_type'].__name__ == 'SAGEConv':\n",
    "                if self.config['batch_normalization']:\n",
    "                    x = self.bn_list[layer_idx](x)\n",
    "                x = self.config['activation_func'](x)\n",
    "                if self.config['dropout'] > 0.0 and self.training: \n",
    "                    x = F.dropout(x, p = self.config['dropout'], training = self.training)               \n",
    "\n",
    "        x_pooled = self.config['pooling_option'](x, batch)\n",
    "\n",
    "        num_layers = len(self.linear_layer_list)\n",
    "        for layer_idx, layer in enumerate(self.linear_layer_list):\n",
    "            x_pooled = layer(x_pooled)\n",
    "            if layer_idx < num_layers - 1:\n",
    "                if self.config['batch_normalization']:\n",
    "                    x_pooled = self.linear_bn_list[layer_idx](x_pooled)\n",
    "                x_pooled = self.config['activation_func'](x_pooled)\n",
    "                if self.config['dropout'] > 0.0 and self.training:\n",
    "                    x_pooled = F.dropout(x_pooled, p = self.config['dropout'], training = self.training)           \n",
    "        \n",
    "        return x, x_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        data_gpu = data.to(device)\n",
    "        _, out = model(data_gpu.x, data_gpu.edge_index, data_gpu.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data_gpu.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "def test(model, loader, criterion):\n",
    "    correct, loss = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            data_gpu = data.to(device)\n",
    "            _, out = model(data_gpu.x, data_gpu.edge_index, data_gpu.batch)   \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            loss += float(criterion(out, data_gpu.y).sum())\n",
    "            correct += int((pred == data_gpu.y).sum())  # Check against ground-truth labels.\n",
    "         \n",
    "    return loss / len(loader.dataset), correct / len(loader.dataset),   # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial_robustness(model, le, criterion, adversarial_graph_addr_list):\n",
    "    original_graph_list, target_graph_list, adversarial_graph_list = [], [], []\n",
    "    original_addr_list, target_addr_list, adversarial_addr_list = [], [], []\n",
    "    original_score_dist, target_score_dist, adversarial_score_dist, failed_adversarial_score_dist = [], [], [], []\n",
    "\n",
    "    original_loss, original_correct = 0, 0\n",
    "    target_loss, target_correct = 0, 0\n",
    "    robust_counter, adversarial_counter, ineffective_counter = 0, 0, 0\n",
    "    original_num_samples, target_num_samples = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in adversarial_graph_addr_list:\n",
    "            adversarial_graph_data = read_graph_data(i)\n",
    "            adversarial_model_data = T.OneHotDegree(max_degree = 187, cat = False, in_degree = True)(process_graph_data(adversarial_graph_data, 'adversarial', le))\n",
    "            adversarial_model_data = Batch.from_data_list([adversarial_model_data])\n",
    "    \n",
    "            original_addr = adversarial_graph_data['description']['original'][0]\n",
    "            original_processed_path, original_label = get_processed_addr(original_addr)\n",
    "            original_graph_data = read_graph_data(original_processed_path)\n",
    "            original_model_data = T.OneHotDegree(max_degree = 187, cat = False, in_degree = True)(process_graph_data(original_graph_data, original_label, le))\n",
    "            original_model_data = Batch.from_data_list([original_model_data])\n",
    "\n",
    "            target_addr = adversarial_graph_data['description']['target'][0]\n",
    "            target_processed_path, target_label = get_processed_addr(target_addr)\n",
    "            target_graph_data = read_graph_data(target_processed_path)\n",
    "            target_model_data = T.OneHotDegree(max_degree = 187, cat = False, in_degree = True)(process_graph_data(target_graph_data, target_label, le))\n",
    "            target_model_data = Batch.from_data_list([target_model_data])\n",
    "\n",
    "            original_model_data = original_model_data.to('cuda')\n",
    "            _, original_out = model(original_model_data.x, original_model_data.edge_index, original_model_data.batch)\n",
    "            original_pred = original_out.argmax(dim=1)\n",
    "    \n",
    "            if original_addr not in original_addr_list:\n",
    "                original_addr_list.append(original_addr)\n",
    "                original_num_samples += 1\n",
    "                original_loss += float(criterion(original_out, original_model_data.y).sum())\n",
    "                original_correct += int((original_pred == original_model_data.y).sum())\n",
    "\n",
    "\n",
    "            target_model_data = target_model_data.to('cuda')\n",
    "            _, target_out = model(target_model_data.x, target_model_data.edge_index, target_model_data.batch)\n",
    "            target_pred = target_out.argmax(dim = 1)\n",
    "\n",
    "\n",
    "            if target_addr not in target_addr_list:\n",
    "                target_addr_list.append(target_addr)\n",
    "                target_num_samples += 1 \n",
    "                \n",
    "                target_loss += float(criterion(target_out, target_model_data.y).sum())\n",
    "                target_correct += int((target_pred == target_model_data.y).sum())\n",
    "            \n",
    "\n",
    "            adversarial_model_data = adversarial_model_data.to('cuda')\n",
    "            _, adversarial_out = model(adversarial_model_data.x, adversarial_model_data.edge_index, adversarial_model_data.batch)\n",
    "\n",
    "            # <<< Softmax >>>\n",
    "            adversarial_pred = adversarial_out.argmax(dim = 1)\n",
    "            \n",
    "            if (original_model_data.y.item() == original_pred.item()) and (target_model_data.y.item() == target_pred.item()):\n",
    "                if adversarial_pred.item() == target_pred.item():\n",
    "                    adversarial_counter += 1\n",
    "                    adversarial_score_dist.append(F.softmax(adversarial_out, dim = 1).max(dim = 1).values.detach().to('cpu').item())\n",
    "                    adversarial_graph_list.append(adversarial_model_data[0].detach().to('cpu')) \n",
    "                else:\n",
    "                    robust_counter += 1\n",
    "                    failed_adversarial_score_dist.append(F.softmax(adversarial_out, dim = 1).max(dim = 1).values.detach().to('cpu').item())\n",
    "            else:\n",
    "                ineffective_counter += 1\n",
    "\n",
    "    print(f'adv counter: {adversarial_counter} - robust counter: {robust_counter} - Ineffective Samples: {ineffective_counter} - Total: {adversarial_counter + robust_counter + ineffective_counter} - adv ratio: {adversarial_counter / (adversarial_counter + robust_counter) if (adversarial_counter + robust_counter) else 0}')\n",
    "\n",
    "    return adversarial_graph_list, adversarial_score_dist, failed_adversarial_score_dist, adversarial_counter, robust_counter, adversarial_counter / (adversarial_counter + robust_counter) if (adversarial_counter + robust_counter) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_confusion_matrix(model, le, adversarial_graph_addr_list):\n",
    "    confustion_matrix = {'benign': 0, 'gafgyt': 0, 'mirai': 0, 'tsunami': 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in adversarial_graph_addr_list:\n",
    "            adversarial_graph_data = read_graph_data(i)\n",
    "            adversarial_model_data = T.OneHotDegree(max_degree = 187, cat = False, in_degree = True)(process_graph_data(adversarial_graph_data, 'adversarial', le))\n",
    "            adversarial_model_data = Batch.from_data_list([adversarial_model_data]).to('cuda')      \n",
    "            _, adversarial_out = model(adversarial_model_data.x, adversarial_model_data.edge_index, adversarial_model_data.batch)\n",
    "            adversarial_pred = adversarial_out.argmax(dim = 1)\n",
    "            confustion_matrix[le.inverse_transform(adversarial_pred.to('cpu'))[0]] += 1\n",
    "\n",
    "    return confustion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_setting(config):\n",
    "    layer_size_str = ''.join(str(s[-1])+'-' for s in config['layer_size_list'])[:-1]\n",
    "    conv_layer_type_str = config['conv_layer_type'].__name__\n",
    "    batch_size_str = str(config['batch_size'])\n",
    "    bn_str = 'batchNorm' if config['batch_normalization'] else 'noBatchNorm'\n",
    "    pooling_str = config['pooling_option'].__name__.split('_')[1] + 'Pool'\n",
    "    dropout_str = 'dropout' + str(config['dropout'])\n",
    "    lr_str = 'lr' + str(config['lr'])\n",
    "\n",
    "    model_setting = f'batchSize{batch_size_str}_{conv_layer_type_str}{layer_size_str}_linear32-32_{pooling_str}_{bn_str}_{dropout_str}_{lr_str}'\n",
    "    return model_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier(config):\n",
    "    save_addr_base = 'classifier'\n",
    "    \n",
    "    classifier = GNN_CLASSIFIER(config).to(device)\n",
    "    optimizer = config['optimizer'](classifier.parameters(), lr=config['lr'])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model_setting = get_model_setting(config)\n",
    "\n",
    "    print('Model Config: {}'.format(model_setting))\n",
    "\n",
    "    dataset_dict = split_dataset(train_dataset, test_dataset, None, config['batch_size'])\n",
    "\n",
    "    ########### training\n",
    "    train_acc_list, test_acc_list = [], []\n",
    "    train_err_list, test_err_list = [], []\n",
    "    Epochs = 150\n",
    "    early_stopping_counter = 0\n",
    "    num_stop_hit = 0\n",
    "    early_stopping_criteria = 15\n",
    "\n",
    "    for epoch in range(Epochs):\n",
    "        train(classifier, dataset_dict['normal']['train'], criterion, optimizer)\n",
    "        train_err, train_acc = test(classifier, dataset_dict['normal']['train'], criterion)\n",
    "        test_err, test_acc = test(classifier, dataset_dict['normal']['total_test'], criterion)\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_err_list.append(train_err)\n",
    "        test_acc_list.append(test_acc)\n",
    "        test_err_list.append(test_err)\n",
    "\n",
    "        print(f'=== Epoch: {epoch + 1} / {Epochs}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, Train err: {train_err:.4f}, Test Err: {test_err:.4f} ===')\n",
    "        \n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.title('{} Accuracy/Epoch\\nMaximum Test Accuracy: {} at Epoch {}'.format(model_setting, np.max(test_acc_list), np.argmax(test_acc_list) + 1))\n",
    "        plt.plot(train_acc_list, label = 'Train')\n",
    "        plt.plot(test_acc_list, label = 'Test')\n",
    "        plt.xticks(range(1, epoch + 2))\n",
    "        plt.xlabel('Epoch') \n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.yticks(np.arange(0, 1.05, 0.05))\n",
    "        plt.savefig(f\"{save_addr_base}/plots/{model_setting}_acc_plot.pdf\")\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.title('{} Loss/Epoch'.format(model_setting))\n",
    "        plt.plot(train_err_list, label = 'Train')\n",
    "        plt.plot(test_err_list, label = 'Test')\n",
    "        plt.xticks(range(1, epoch + 2))\n",
    "        plt.xlabel('Epoch') \n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_addr_base}/plots/{model_setting}_err_plot.pdf\")\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        if epoch > 0:\n",
    "            max_test_acc = max(test_acc_list[:-1])\n",
    "            if test_acc > max_test_acc:\n",
    "                print('Best test accuracy so far.')\n",
    "                early_stopping_counter = 0\n",
    "                torch.save(classifier, f\"{save_addr_base}/models/{model_setting}\")  \n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print('No improvement.')\n",
    "\n",
    "                if early_stopping_counter == early_stopping_criteria:\n",
    "                    num_stop_hit += 1\n",
    "                    if num_stop_hit == 4:\n",
    "                        print('Stop training.')\n",
    "                        break\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = 0.1 * param_group['lr']\n",
    "                    classifier = torch.load(f\"{save_addr_base}/models/{model_setting}\").to(device)\n",
    "                    print(f'Reducing lr. Number of Stop hits: {num_stop_hit}')\n",
    "                    early_stopping_counter = 0\n",
    "\n",
    "        else:\n",
    "            torch.save(classifier, f\"{save_addr_base}/models/{model_setting}\")   \n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    print('Model Config: {}'.format(model_setting))\n",
    "\n",
    "    ########## load model\n",
    "    classifier = torch.load(f\"{save_addr_base}/models/{model_setting}\").to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    classifier.eval()\n",
    "\n",
    "    for k, v in dataset_dict['normal'].items():\n",
    "        if 'test' in k:\n",
    "            test_err, test_acc = test(classifier, v, criterion)\n",
    "            print(f'Evaluation on Normal {k} Data ({len(v.dataset)}) --> Error: {test_err}, Accuracy: {test_acc}')\n",
    "\n",
    "    ########## Find Normal Data Output Distribution\n",
    "    train_benign_score_dist, test_benign_score_dist = [], []\n",
    "    train_gafgyt_score_dist, test_gafgyt_score_dist,  = [], []\n",
    "    train_mirai_score_dist, test_mirai_score_dist = [], []\n",
    "    train_tsunami_score_dist, test_tsunami_score_dist = [], []\n",
    "\n",
    "    for data_split, loader in dataset_dict['normal'].items():\n",
    "        benign_dist = []\n",
    "        gafgyt_dist = []\n",
    "        mirai_dist = []\n",
    "        tsunami_dist = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "                data_gpu = data.to(device)\n",
    "                _, out = classifier(data_gpu.x, data_gpu.edge_index, data_gpu.batch)   \n",
    "                pred = F.softmax(out, dim = 1).max(dim = 1).values.detach().to('cpu')\n",
    "\n",
    "                for y, y_hat in zip(data.detach().to('cpu').y.tolist(), pred.tolist()):\n",
    "                    if y == le.transform(['benign'])[0]:\n",
    "                        benign_dist.append(y_hat)\n",
    "                    elif y == le.transform(['tsunami'])[0]:\n",
    "                        tsunami_dist.append(y_hat)\n",
    "                    elif y == le.transform(['mirai'])[0]:\n",
    "                        mirai_dist.append(y_hat)\n",
    "                    elif y == le.transform(['gafgyt'])[0]:\n",
    "                        gafgyt_dist.append(y_hat)\n",
    "\n",
    "        if data_split == 'train':\n",
    "            train_benign_score_dist = benign_dist[:]\n",
    "            train_tsunami_score_dist = tsunami_dist[:]\n",
    "            train_mirai_score_dist = mirai_dist[:]\n",
    "            train_gafgyt_score_dist = gafgyt_dist[:]\n",
    "        elif data_split == 'test':\n",
    "            test_benign_score_dist = benign_dist[:]\n",
    "            test_tsunami_score_dist = tsunami_dist[:]\n",
    "            test_mirai_score_dist = mirai_dist[:]\n",
    "            test_gafgyt_score_dist = gafgyt_dist[:]\n",
    "            \n",
    "\n",
    "    print(f\"Train Benign Scores: {len(train_benign_score_dist)}, Test Benign Scores: {len(test_benign_score_dist)}\")\n",
    "    print(f\"Train gafgyt Scores: {len(train_gafgyt_score_dist)}, Test gafgyt Scores: {len(test_gafgyt_score_dist)}\")\n",
    "    print(f\"Train mirai Scores: {len(train_mirai_score_dist)}, Test mirai Scores: {len(test_mirai_score_dist)}\")\n",
    "    print(f\"Train tsunami Scores: {len(train_tsunami_score_dist)}, Test tsunami Scores: {len(test_tsunami_score_dist)}\")\n",
    "\n",
    "    print(f\"Number of Adversarial Addresses --> Benign: {len(adv_addr_dict['adversarial_benign'])} - Gafgyt: {len(adv_addr_dict['adversarial_gafgyt'])} - Mirai: {len(adv_addr_dict['adversarial_mirai'])} - Tsunami: {len(adv_addr_dict['adversarial_tsunami'])}\")\n",
    "\n",
    "    adv_metric_dict = {'adversarial_benign': None, 'adversarial_gafgyt': None, 'adversarial_mirai': None, 'adversarial_tsunami': None}\n",
    "    for adv_k, adv_v in adv_addr_dict.items():\n",
    "        adversarial_graph_list, adversarial_score_dist, failed_adversarial_score_dist, adversarial_counter, robust_counter, robustness_ratio = test_adversarial_robustness(classifier, le, criterion, adv_v['min'] + adv_v['median'] + adv_v['max'])\n",
    "        adv_ratio = adversarial_counter / (adversarial_counter + robust_counter) if (adversarial_counter + robust_counter) else 0\n",
    "        print(f'Adversarial Report for {adv_k}: ', adversarial_counter, robust_counter, adv_ratio, len(adversarial_score_dist + failed_adversarial_score_dist))\n",
    "        adv_metric_dict[adv_k] = (adversarial_counter, robust_counter, adv_ratio)\n",
    "    with open(f\"{save_addr_base}/logs/adversarialReport_config-{model_setting}.txt\", 'w') as f:\n",
    "        f.write(json.dumps(adv_metric_dict))\n",
    "\n",
    "    print('=================')\n",
    "    for adv_k, adv_v in adv_addr_dict.items():\n",
    "        for sub_adv_k, sub_adv_v in adv_v.items():\n",
    "            cf = get_adversarial_confusion_matrix(classifier, le, sub_adv_v)\n",
    "            print(adv_k, sub_adv_k, sum(cf.values()), cf)\n",
    "        print('-----------')\n",
    "\n",
    "    plot_histogram(\n",
    "        data_list = [train_benign_score_dist, test_benign_score_dist, train_tsunami_score_dist, test_tsunami_score_dist, train_mirai_score_dist, test_mirai_score_dist, train_gafgyt_score_dist, test_gafgyt_score_dist, adversarial_score_dist],\n",
    "        num_bins = 300,\n",
    "        legend_list = ['Benign Train', 'Benign Test', 'Tsunami Train', 'Tsunami Test', 'Mirai Train', 'Mirai Test', 'Gafgyt Train', 'Gafgyt Test', 'Adversarial'],\n",
    "        title = f'Max softmax distribution of all subsets for {model_setting}', x_label = 'Softmax Score', y_label = 'Number of Samples', save_path = f'{save_addr_base}/plots/all_scores_{model_setting}.pdf'\n",
    "    ) \n",
    "    \n",
    "    plot_histogram(\n",
    "        data_list = [adversarial_score_dist, failed_adversarial_score_dist], \n",
    "        num_bins = 300,\n",
    "        legend_list = ['Adversarial', 'Failed Adversarial'],\n",
    "        title = f'Max softmax distribution of adversarial samples for {model_setting}', x_label = 'Softmax Score', y_label = 'Number of Samples', save_path = f'{save_addr_base}/plots/adversrial_scores_{model_setting}.pdf'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in [\n",
    "  {'lr': 0.01, 'batch_size': 128, 'dropout': 0.0, 'optimizer': torch.optim.Adam, 'virtual_edges': False, 'conv_layer_type': SAGEConv, 'layer_size_list': [(188, 64), (64, 64), (64, 32)], 'conv_normalize': False, 'batch_normalization': True, 'pooling_option': global_add_pool, 'activation_func': F.relu},\n",
    "]:\n",
    "  print('<<<<<<<<<<<<<<<< >>>>>>>>>>>>>>>>>')\n",
    "  train_test_classifier(config) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a563c4fea09d6faebdb5e5ac3287d5ca559a69631ad74c32f34398c0910a8f01"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('PyG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
